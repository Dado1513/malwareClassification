import org.apache.commons.io.FilenameUtils;
import org.apache.commons.io.filefilter.FileFileFilter;
import org.datavec.api.io.filters.BalancedPathFilter;
import org.datavec.api.io.labels.ParentPathLabelGenerator;
import org.datavec.api.split.FileSplit;
import org.datavec.api.split.InputSplit;
import org.datavec.image.loader.NativeImageLoader;
import org.datavec.image.recordreader.ImageRecordReader;
import org.deeplearning4j.api.storage.StatsStorage;
import org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator;
import org.deeplearning4j.datasets.iterator.MultipleEpochsIterator;
import org.deeplearning4j.eval.Evaluation;
import org.deeplearning4j.eval.IEvaluation;
import org.deeplearning4j.eval.ROC;
import org.deeplearning4j.eval.ROCMultiClass;
import org.deeplearning4j.evaluation.EvaluationTools;
import org.deeplearning4j.nn.api.Model;
import org.deeplearning4j.nn.api.OptimizationAlgorithm;
import org.deeplearning4j.nn.conf.LearningRatePolicy;
import org.deeplearning4j.nn.conf.MultiLayerConfiguration;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration;
import org.deeplearning4j.nn.conf.Updater;
import org.deeplearning4j.nn.conf.distribution.Distribution;
import org.deeplearning4j.nn.conf.distribution.GaussianDistribution;
import org.deeplearning4j.nn.conf.inputs.InputType;
import org.deeplearning4j.nn.conf.layers.*;
import org.deeplearning4j.nn.graph.ComputationGraph;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.deeplearning4j.nn.transferlearning.FineTuneConfiguration;
import org.deeplearning4j.nn.transferlearning.TransferLearning;
import org.deeplearning4j.nn.weights.WeightInit;
import org.deeplearning4j.optimize.listeners.ScoreIterationListener;
import org.deeplearning4j.ui.api.UIServer;
import org.deeplearning4j.ui.stats.StatsListener;
import org.deeplearning4j.ui.storage.InMemoryStatsStorage;
import org.deeplearning4j.util.ModelSerializer;
import org.deeplearning4j.zoo.PretrainedType;
import org.deeplearning4j.zoo.ZooModel;
import org.deeplearning4j.zoo.model.AlexNet;
import org.deeplearning4j.zoo.model.ResNet50;
import org.deeplearning4j.zoo.model.VGG16;
import org.nd4j.linalg.activations.Activation;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.api.ops.impl.transforms.LeakyReLU;
import org.nd4j.linalg.dataset.api.DataSet;
import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;
import org.nd4j.linalg.dataset.api.preprocessor.DataNormalization;
import org.nd4j.linalg.dataset.api.preprocessor.ImagePreProcessingScaler;
import org.nd4j.linalg.dataset.api.preprocessor.VGG16ImagePreProcessor;
import org.nd4j.linalg.factory.Nd4j;
import org.nd4j.linalg.learning.config.Nesterovs;
import org.nd4j.linalg.lossfunctions.LossFunctions;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.awt.image.Kernel;
import java.io.File;
import java.io.FilenameFilter;
import java.io.IOException;
import java.io.PrintWriter;
import java.util.ArrayList;
import java.util.List;
import java.util.Random;
import java.util.Scanner;

public class MainMalware {
    protected static final Logger log = LoggerFactory.getLogger(MainMalware.class);
    protected static int height = 32;
    protected static int width = 32;
    protected static int channels = 1;
    protected static int numExamples = 9338;
    protected static int numLabels = 25;
    protected static int batchSize = 200;
    protected static double learningRate = 0.0094;
    protected static double l2 = 0.01;
    protected static double dropout = 0.85;
    protected static long seed = 42;
    protected static Random rng = new Random(seed);
    protected static int iterations = 1;
    protected static int epochs = 100;
    protected static double splitTrainTest = 0.8;
    protected static boolean save = false;

    public void run(String[] args) throws Exception {

        // create dir for file and get inputsplit
        long timestart = System.currentTimeMillis();

        ParentPathLabelGenerator labelMaker = new ParentPathLabelGenerator();
        InputSplit[] inputSplits = new SplitTrainTest().run(args,splitTrainTest);
        InputSplit trainData = inputSplits[0];
        InputSplit testData = inputSplits[1];

        MultiLayerNetworkMalware builderNet = new MultiLayerNetworkMalware(channels,width,height,seed,dropout,learningRate,numLabels,l2,iterations);
        //MultiLayerNetwork network = builderNet.getVGG16();
        //MultiLayerNetwork network = builderNet.malwareNet(); // learning rate = 0.005 l2 = 0.01 epoche  100

        // far scegliere all'utente la rete che vuole usare
        System.out.println("Choose type CNN: ");
        System.out.println("1 for LeNet");
        System.out.println("2 for MalwareNet");
        System.out.println("3 for MalwareNetWeighted");

        Scanner in = new Scanner(System.in);
        System.out.print(">> ");
        int choose = in.nextInt();
        String type;
        MultiLayerNetwork network;


        switch(choose){
            case 1:
                System.out.println("Selected LeNet");
                network = builderNet.leNetModel();
                type = "LeNet";
                break;
            case 2:
                System.out.println("Selected MalwareNet");
                network = builderNet.malwareNet();
                type = "MalwareNet";

                break;
            case 3:
                System.out.println("Selected MalwareNetWeighted");
                network = builderNet.malwareNetWeighted(getWeightedBasedOnFrequency(trainData.length(),numLabels));
                type = "MalwareNetWeighted";

                break;
            default:
                System.out.println("Selected default CNN --> MalwareNet");
                network = builderNet.malwareNet();
                type = "MalwareNet";


                break;
        }


        DataNormalization scaler = new ImagePreProcessingScaler(0, 1);

        UIServer uiServer = UIServer.getInstance();
        StatsStorage statsStorage = new InMemoryStatsStorage();
        network.setListeners(new StatsListener(statsStorage, 1), new ScoreIterationListener(iterations));
        uiServer.attach(statsStorage);
        Scanner input = new Scanner(System.in);

        ImageRecordReader recordReaderTest = new ImageRecordReader(height, width, channels, labelMaker);
        ImageRecordReader recordReaderTrain = new ImageRecordReader(height, width, channels, labelMaker);
        DataSetIterator dataIterTest;
        DataSetIterator dataIterTrain;
        recordReaderTest.initialize(testData);
        recordReaderTrain.initialize(trainData);

        dataIterTest = new RecordReaderDataSetIterator(recordReaderTest, batchSize, 1, numLabels);
        dataIterTrain = new RecordReaderDataSetIterator(recordReaderTrain, batchSize, 1, numLabels);

        dataIterTest.setPreProcessor(scaler);
        dataIterTrain.setPreProcessor(scaler);

        // fit net
        MultipleEpochsIterator trainIter;
        trainIter = new MultipleEpochsIterator(epochs, dataIterTrain);
        network.fit(trainIter);

        System.out.println("Finish... Evaluation...");
        Evaluation eval ;
        //eval = network.evaluate(dataIterTest);
        // more evaluation ROC e eval
        ROCMultiClass roc;
        IEvaluation[] iEvaluations = network.doEvaluation(dataIterTest,new Evaluation(numLabels),new ROCMultiClass());
        //eval = (Evaluation)iEvaluations[0];
        //roc = (ROCMultiClass)iEvaluations[1];
        roc = network.evaluateROCMultiClass(dataIterTest,0);
        eval = network.evaluate(dataIterTest);

        System.out.println(eval.stats() + "\n");
        System.out.println(eval.confusionToString());
        System.gc();

        // print to file result
        String dirName = System.getProperty("user.dir")+"/src/main/resources/ResultLenet/";
        File dirResultLeNet = new File(dirName);
        // lamba function
        FilenameFilter textFilter = (dir, name) -> { return name.endsWith(".txt"); };
        int index_result = dirResultLeNet.listFiles(textFilter).length;

        long timeend = System.currentTimeMillis();
        long executionTime = timeend -timestart;
        double secondTime = (double)executionTime*Math.pow(10,-3);
        double minutTime = secondTime/60;
        index_result = index_result+1;
        PrintWriter pw = new PrintWriter(dirName+"result_"+index_result+".txt");
        pw.println(network.conf().toJson());
        pw.println("Type input : "+args[0]);
        pw.println("Batchsize : " +batchSize);
        pw.println("Epoche : "+epochs);
        pw.println("Split train: " + splitTrainTest*100 +" %");
        pw.println("Execution time :" + minutTime+ " m");
        pw.println("TYpeNet : "+type);
        pw.println(eval.stats());
        pw.println();
        pw.println(eval.confusionToString());

        pw.close();
        EvaluationTools.exportRocChartsToHtmlFile(roc,new File(dirName+"result_roc_"+index_result+".html"));


        // single test
        dataIterTest.reset();
        DataSet testDataSet = dataIterTest.next();
        List<String> allClassLabels = recordReaderTest.getLabels();
        INDArray predictedClasses = network.output(testDataSet.getFeatures());
        System.out.println("True " + allClassLabels.get(testDataSet.getLabels().argMax(1).getInt(0)));
        System.out.println("Predict " + allClassLabels.get(predictedClasses.argMax(1).getInt(0)));
        System.exit(0);
    }

    // to prevent error based on dataset unbalanced
    private static INDArray getWeightedBasedOnFrequency(long totalTrainData,int numLabels ){
        String dir = System.getProperty("user.dir")+"/" +
                "src/main/resources/training_set/malware_";
        double [] weightedArray = new double[numLabels];
        for (int i = 1;i<26;i++){

            File fileDir = new File(dir+i);
            int nMalwarei = fileDir.listFiles().length;
            double weighted = 1 - nMalwarei/totalTrainData;
            weightedArray[i-1] = weighted;
        }

        INDArray array = Nd4j.create(weightedArray);
        return array;
    }

    public static void main(String[] args) throws Exception {
        new MainMalware().run(args);

    }
}
