import org.apache.commons.io.FilenameUtils;
import org.apache.commons.io.filefilter.FileFileFilter;
import org.datavec.api.io.filters.BalancedPathFilter;
import org.datavec.api.io.labels.ParentPathLabelGenerator;
import org.datavec.api.split.FileSplit;
import org.datavec.api.split.InputSplit;
import org.datavec.image.loader.NativeImageLoader;
import org.datavec.image.recordreader.ImageRecordReader;
import org.deeplearning4j.api.storage.StatsStorage;
import org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator;
import org.deeplearning4j.datasets.iterator.MultipleEpochsIterator;
import org.deeplearning4j.eval.Evaluation;
import org.deeplearning4j.eval.IEvaluation;
import org.deeplearning4j.eval.ROC;
import org.deeplearning4j.eval.ROCMultiClass;
import org.deeplearning4j.evaluation.EvaluationTools;
import org.deeplearning4j.nn.api.Model;
import org.deeplearning4j.nn.api.OptimizationAlgorithm;
import org.deeplearning4j.nn.conf.LearningRatePolicy;
import org.deeplearning4j.nn.conf.MultiLayerConfiguration;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration;
import org.deeplearning4j.nn.conf.Updater;
import org.deeplearning4j.nn.conf.distribution.Distribution;
import org.deeplearning4j.nn.conf.distribution.GaussianDistribution;
import org.deeplearning4j.nn.conf.inputs.InputType;
import org.deeplearning4j.nn.conf.layers.*;
import org.deeplearning4j.nn.graph.ComputationGraph;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.deeplearning4j.nn.transferlearning.FineTuneConfiguration;
import org.deeplearning4j.nn.transferlearning.TransferLearning;
import org.deeplearning4j.nn.weights.WeightInit;
import org.deeplearning4j.optimize.listeners.ScoreIterationListener;
import org.deeplearning4j.ui.api.UIServer;
import org.deeplearning4j.ui.stats.StatsListener;
import org.deeplearning4j.ui.storage.InMemoryStatsStorage;
import org.deeplearning4j.util.ModelSerializer;
import org.deeplearning4j.zoo.PretrainedType;
import org.deeplearning4j.zoo.ZooModel;
import org.deeplearning4j.zoo.model.AlexNet;
import org.deeplearning4j.zoo.model.ResNet50;
import org.deeplearning4j.zoo.model.VGG16;
import org.nd4j.linalg.activations.Activation;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.api.ops.impl.transforms.LeakyReLU;
import org.nd4j.linalg.dataset.api.DataSet;
import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;
import org.nd4j.linalg.dataset.api.preprocessor.DataNormalization;
import org.nd4j.linalg.dataset.api.preprocessor.ImagePreProcessingScaler;
import org.nd4j.linalg.dataset.api.preprocessor.VGG16ImagePreProcessor;
import org.nd4j.linalg.learning.config.Nesterovs;
import org.nd4j.linalg.lossfunctions.LossFunctions;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.awt.image.Kernel;
import java.io.File;
import java.io.FilenameFilter;
import java.io.IOException;
import java.io.PrintWriter;
import java.util.List;
import java.util.Random;
import java.util.Scanner;

public class MainMalware {
    protected static final Logger log = LoggerFactory.getLogger(MainMalware.class);
    protected static int height = 32;
    protected static int width = 32;
    protected static int channels = 1;
    protected static int numExamples = 9338;
    protected static int numLabels = 25;
    protected static int batchSize = 200;
    protected static double learningRate = 0.01;
    protected static double l2 = 0.001;
    protected static double dropout = 0.85;
    protected static long seed = 42;
    protected static Random rng = new Random(seed);
    protected static int iterations = 1;
    protected static int epochs = 100;
    protected static double splitTrainTest = 0.7;
    protected static boolean save = false;

    public void run(String[] args) throws Exception {

        // create dir for file and get inputsplit
        long timestart = System.currentTimeMillis();

        ParentPathLabelGenerator labelMaker = new ParentPathLabelGenerator();
        InputSplit[] inputSplits = new SplitTrainTest().run(args);
        InputSplit trainData = inputSplits[0];
        InputSplit testData = inputSplits[1];

        //MultiLayerNetwork network = leNetModel();
        System.out.println("Choose net: ");
        System.out.println("1) LeNet");
        System.out.println("2) MalwareNet");
        System.out.println("3) VGG16");

        Scanner in = new Scanner(System.in);
        System.out.print(">> ");
        //int choose = in.nextInt();


        MultiLayerNetwork network = leNetModel();

        DataNormalization scaler = new ImagePreProcessingScaler(0, 1);

        UIServer uiServer = UIServer.getInstance();
        StatsStorage statsStorage = new InMemoryStatsStorage();
        network.setListeners(new StatsListener(statsStorage, 1), new ScoreIterationListener(iterations));
        uiServer.attach(statsStorage);

        ImageRecordReader recordReaderTest = new ImageRecordReader(height, width, channels, labelMaker);
        ImageRecordReader recordReaderTrain = new ImageRecordReader(height, width, channels, labelMaker);
        DataSetIterator dataIterTest;
        DataSetIterator dataIterTrain;
        recordReaderTest.initialize(testData);
        recordReaderTrain.initialize(trainData);
        dataIterTest = new RecordReaderDataSetIterator(recordReaderTest, batchSize, 1, numLabels);
        dataIterTrain = new RecordReaderDataSetIterator(recordReaderTrain, batchSize, 1, numLabels);
        dataIterTest.setPreProcessor(scaler);
        dataIterTrain.setPreProcessor(scaler);

        // fit net
        MultipleEpochsIterator trainIter;
        trainIter = new MultipleEpochsIterator(epochs, dataIterTrain);
        network.fit(trainIter);

        System.out.println("Finish... Evaluation...");
        Evaluation eval ;
        //eval = network.evaluate(dataIterTest);
        // more evaluation ROC e eval
        ROCMultiClass roc;
        IEvaluation[] iEvaluations = network.doEvaluation(dataIterTest,new Evaluation(numLabels),new ROCMultiClass());
        eval = (Evaluation)iEvaluations[0];
        roc = (ROCMultiClass)iEvaluations[1];

        System.out.println(eval.stats() + "\n");
        System.out.println(eval.confusionToString());
        System.gc();

        // print to file result
        String dirName = System.getProperty("user.dir")+"/src/main/resources/ResultLenet/";
        File dirResultLeNet = new File(dirName);
        // lamba function
        FilenameFilter textFilter = (dir, name) -> { return name.endsWith(".txt"); };
        int index_result = dirResultLeNet.listFiles(textFilter).length;

        long timeend = System.currentTimeMillis();
        long executionTime = timeend -timestart;
        double secondTime = (double)executionTime*Math.pow(10,-3);
        double minutTime = secondTime/60;
        index_result = index_result+1;
        PrintWriter pw = new PrintWriter(dirName+"result_"+index_result+".txt");
        pw.println(network.conf().toString());
        pw.println("Type input : "+args[0]);
        pw.println("Batchsize : " +batchSize);
        pw.println("Epoche : "+epochs);

        pw.println("Execution time :" + minutTime+ " m");
        pw.println(eval.stats());
        pw.println();
        pw.println(eval.confusionToString());

        pw.close();
        EvaluationTools.exportRocChartsToHtmlFile(roc,new File(dirName+"result_roc_"+index_result+".html"));


        // single test
        dataIterTest.reset();
        DataSet testDataSet = dataIterTest.next();
        List<String> allClassLabels = recordReaderTest.getLabels();
        INDArray predictedClasses = network.output(testDataSet.getFeatures());
        System.out.println("True " + allClassLabels.get(testDataSet.getLabels().argMax(1).getInt(0)));
        System.out.println("Predict " + allClassLabels.get(predictedClasses.argMax(1).getInt(0)));
        System.exit(0);
    }

    private ConvolutionLayer convInit(String name, int in, int out, int[] kernel, int[] stride, int[] pad, double bias) {
        return new ConvolutionLayer.Builder(kernel, stride, pad).name(name).nIn(in).nOut(out).biasInit(bias).build();
    }

    private ConvolutionLayer conv3x3(String name, int out, double bias) {
        return new ConvolutionLayer.Builder(new int[]{3, 3}, new int[]{1, 1}, new int[]{1, 1}).name(name).nOut(out).biasInit(bias).build();
    }

    private ConvolutionLayer conv5x5(String name, int out, int[] stride, int[] pad, double bias) {
        return new ConvolutionLayer.Builder(new int[]{5, 5}, stride, pad).name(name).nOut(out).biasInit(bias).build();
    }

    private SubsamplingLayer maxPool(String name, int[] kernel) {
        return new SubsamplingLayer.Builder(kernel, new int[]{2, 2}).name(name).build();
    }

    private DenseLayer fullyConnected(String name, int out, double bias, double dropOut, Distribution dist) {
        return new DenseLayer.Builder().name(name).nOut(out).biasInit(bias).dropOut(dropOut).dist(dist).build();
    }

    // my lenet model
    public MultiLayerNetwork leNetModel() {

        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
                .seed(seed)
                .iterations(iterations)
                .regularization(true).l2(l2)
                .activation(Activation.RELU)
                .learningRate(learningRate)
                .weightInit(WeightInit.XAVIER_LEGACY)
                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
                .updater(new Nesterovs(0.9))
                .list()
                .layer(0, convInit("cnn1", channels, 50, new int[]{5, 5}, new int[]{1, 1}, new int[]{0, 0}, 0))
                .layer(1, maxPool("maxpool1", new int[]{2, 2}))
                .layer(2, conv5x5("cnn2", 100, new int[]{5, 5}, new int[]{1, 1}, 0))
                .layer(3, maxPool("maxpool2", new int[]{2, 2}))
                .layer(4, new DenseLayer.Builder().nOut(500).build())
                .layer(5, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)
                        .nOut(numLabels)
                        .activation(Activation.SOFTMAX)
                        .build())
                .backprop(true).pretrain(false)
                .setInputType(InputType.convolutional(height, width, channels))
                .build();

        return new MultiLayerNetwork(conf);
    }

    // net on paper
    public MultiLayerNetwork malwareNet() {

        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
                .seed(seed)
                .iterations(iterations)
                .regularization(true).dropOut(dropout) // tried 0.0001, 0.0005
                .activation(Activation.LEAKYRELU)
                .learningRate(learningRate)// tried 0.00001, 0.00005, 0.000001
                .weightInit(WeightInit.XAVIER_LEGACY)
                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
                .updater(new Nesterovs(0.9))
                .list()
                .layer(0, convInit("cnn1", channels, 36, new int[]{5, 5}, new int[]{1, 1}, new int[]{0, 0}, 0))
                .layer(1, new SubsamplingLayer.Builder(new int[]{2,2}, new int[]{1, 1}).name("maxpool").build())
                .layer(2, conv5x5("cnn2", 72, new int[]{5, 5}, new int[]{1, 1}, 0))
                .layer(3, new SubsamplingLayer.Builder(new int[]{2,2}, new int[]{1, 1}).name("maxpool2").build())
                .layer(4, new DenseLayer.Builder().nOut(1024).build())
                .layer(5, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)
                        .nOut(numLabels)
                        .activation(Activation.SOFTMAX)
                        .build())
                .backprop(true).pretrain(false)
                .setInputType(InputType.convolutional(height, width, channels))
                .build();

        return new MultiLayerNetwork(conf);
    }

    public static void main(String[] args) throws Exception {
        new MainMalware().run(args);

    }
}
